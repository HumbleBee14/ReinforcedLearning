# P6: Roopik Code Agent with RLVR

> **Goal:** Build a coding agent evaluation system using Roopik IDE with Verifiable Rewards.

## What We'll Learn

- RLVR (Reinforcement Learning from Verifiable Rewards)
- Using code execution as objective reward signal
- AI-as-judge (RLAIF) for subjective evaluation
- Building preference datasets from execution feedback
- End-to-end agent evaluation pipeline

## Key Concept: RLVR

```
RLHF:  Human says "Response A is better" (subjective)
  â†“
RLAIF: AI says "Response A is better" (cheaper but still subjective)
  â†“
RLVR:  Code compiles? Tests pass? (OBJECTIVE & VERIFIABLE!)

RLVR = The gold standard for coding agents!
```

## Why RLVR is Perfect for Code

| Reward Signal | Type | Example |
|--------------|------|---------|
| Compilation | Verifiable âœ… | Does it compile without errors? |
| Tests | Verifiable âœ… | Do unit tests pass? |
| Execution | Verifiable âœ… | Does it run without crashing? |
| Visual Output | Semi-verifiable | Does screenshot match expected? |
| Code Quality | Subjective | Is it readable? (needs AI judge) |


---
### The RL for LLMs Family Tree

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RL FOR LLMs: THE FAMILY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  RLHF (2022)                                                        â”‚
â”‚  â””â”€â”€ Human preferences â†’ Reward Model â†’ PPO                         â”‚
â”‚  â””â”€â”€ Problem: Humans are expensive, subjective, inconsistent        â”‚
â”‚                                                                     â”‚
â”‚  RLAIF (2023)                                                       â”‚
â”‚  â””â”€â”€ AI as judge instead of humans                                  â”‚
â”‚  â””â”€â”€ Problem: Still subjective (just AI's opinion)                  â”‚
â”‚                                                                     â”‚
â”‚  RLVR (2024) â† YOU'RE LEARNING THIS!                                â”‚
â”‚  â””â”€â”€ Verifiable/Objective rewards                                   â”‚
â”‚  â””â”€â”€ Code: Compiles? Tests pass? Output correct?                    â”‚
â”‚  â””â”€â”€ Math: Answer matches? Proof valid?                             â”‚
â”‚  â””â”€â”€ NO HUMAN NEEDED - just run the code!                           â”‚
â”‚                                                                     â”‚
â”‚  Our Plan: RLVR + RLAIF (Best of both!)                             â”‚
â”‚  â””â”€â”€ Verifiable: Compilation, execution, tests (objective)          â”‚
â”‚  â””â”€â”€ AI Judge: Code quality, readability (subjective)               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

```
# Your Roopik reward function = RLVR!
reward = (
    0.3 * compiled +           # VERIFIABLE âœ…
    0.2 * (1 - error_rate) +   # VERIFIABLE âœ…
    0.3 * tests_pass +         # VERIFIABLE âœ…
    0.1 * ai_judge_quality +   # RLAIF (subjective)
    0.1 * ai_judge_match       # RLAIF (subjective)
)

```


---
## Architecture

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 ROOPIK IDE                      â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
Prompt â”€â”€â”€â”€>â”‚  â”‚ 1. Code Generation (LLM)                  â”‚  â”‚
            â”‚  â”‚ 2. Sandbox Execution                      â”‚  â”‚
            â”‚  â”‚ 3. Capture: errors, output, screenshot    â”‚  â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            REWARD CALCULATION                   â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
            â”‚  â”‚ Verifiable Rewards (RLVR):                â”‚  â”‚
            â”‚  â”‚   - compiled: +0.3                        â”‚  â”‚
            â”‚  â”‚   - no_errors: +0.2                       â”‚  â”‚
            â”‚  â”‚   - tests_pass: +0.3                      â”‚  â”‚
            â”‚  â”‚                                           â”‚  â”‚
            â”‚  â”‚ AI Judge (RLAIF):                         â”‚  â”‚
            â”‚  â”‚   - code_quality: +0.1                    â”‚  â”‚
            â”‚  â”‚   - matches_prompt: +0.1                  â”‚  â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         PREFERENCE DATASET                      â”‚
            â”‚  { prompt, chosen, rejected, scores }           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- âœ… P0-P5: All RL and LLM fine-tuning foundations
- âœ… Roopik IDE running locally

## Files (To Be Created)

```
P6/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ code_generator.py      # LLM code generation
â”œâ”€â”€ executor.py            # Roopik sandbox integration
â”œâ”€â”€ reward_calculator.py   # RLVR + RLAIF rewards
â”œâ”€â”€ ai_judge.py            # AI judge prompts
â”œâ”€â”€ preference_logger.py   # Log preference pairs
â””â”€â”€ run_evaluation.py      # Main evaluation loop
```

## Status: ğŸ¯ The Final Goal!
