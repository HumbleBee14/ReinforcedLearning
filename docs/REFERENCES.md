# Learning References

A curated collection of resources for learning Reinforcement Learning, from fundamentals to advanced topics.

---

## Courses & Tutorials

### Comprehensive Courses
- [RL Fundamentals - Hugging Face Deep RL Course](https://huggingface.co/learn/deep-rl-course/unit0/introduction)
  - Beginner-friendly introduction to RL concepts
  - Hands-on projects with modern libraries

- [David Silver's RL Course (DeepMind)](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)
  - Classic foundational course from DeepMind
  - Mathematical rigor with practical examples

- [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/)
  - OpenAI's educational resource
  - Deep dive into policy gradient methods

---

## Blog Series & Articles

- [RL Blogs by Ketan Doshi](https://medium.com/data-science/reinforcement-learning-made-simple-part-1-intro-to-basic-concepts-and-terminology-1d2a87aa060)
  - **Highly recommended:** Read the entire series
  - Breaks down complex concepts into digestible parts
  - Great for building intuition

- [Deep Q-Networks Explained - LessWrong](https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained)
  - Detailed breakdown of DQN architecture
  - Explains the "why" behind design decisions

- [Neural Breakdown with AVB (Video)](https://www.youtube.com/watch?v=Qpx6WD0qekQ)
  - Visual explanations of neural network concepts - Excellent!

---

## Research Papers

### Foundational Papers
- [DQN Paper](https://arxiv.org/abs/1312.5602) - Playing Atari with Deep RL
  - The paper that started the deep RL revolution
  - Introduces experience replay and target networks

- [PPO Paper](https://arxiv.org/abs/1707.06347) - Proximal Policy Optimization
  - Modern policy gradient method
  - Used for training LLMs with RLHF

### LLM-Specific Papers
- [InstructGPT Paper](https://arxiv.org/abs/2203.02155) - RLHF for LLMs
  - How OpenAI trained ChatGPT with human feedback
  - Foundation for modern LLM alignment

- [DPO Paper](https://arxiv.org/abs/2305.18290) - Direct Preference Optimization
  - Alternative to PPO for LLM training
  - Simpler and more stable

---

## Libraries & Tools

### Core RL Libraries
- [Gymnasium](https://gymnasium.farama.org/)
  - Standard RL environment library
  - Successor to OpenAI Gym

- [Stable Baselines3](https://stable-baselines3.readthedocs.io/)
  - Production-ready RL algorithm implementations
  - Easy to use, well-documented

### LLM Training
- [TRL (Transformer Reinforcement Learning)](https://huggingface.co/docs/trl/)
  - Hugging Face library for training LLMs with RL
  - Supports PPO, DPO, and more

---
